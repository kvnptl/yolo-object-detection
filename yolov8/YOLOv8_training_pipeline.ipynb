{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "m2yQrsczCsGc"
   },
   "source": [
    "# YOLOv8 Training script\n",
    "\n",
    "Author: Kevin Patel\n",
    "\n",
    "Date: 4-July-2023\n",
    "\n",
    "Reference: [Ultralytics github repository](https://github.com/ultralytics/ultralytics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YDkUcgESddUY"
   },
   "source": [
    "### Install"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mlIqGP_7dZAp"
   },
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset for RoboCup 2023 competition | Source: [HBRS Bib cloud](https://bib-cloud.bib.hochschule-bonn-rhein-sieg.de/apps/files/?dir=/Shared/b-it-bots-ds/atwork/images/object_detection/YOLO/robocup_2023_dataset&fileid=16051420) (require HBRS library login credential)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is structured in the following manner:\n",
    "\n",
    "```\n",
    "├── README.md\n",
    "├── robocup_2023_dataset\n",
    "        train\n",
    "        ├── images\n",
    "        └── labels\n",
    "        val\n",
    "        ├── images\n",
    "        └── labels\n",
    "        dataset.yaml\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset YAML File\n",
    "\n",
    "The dataset YAML (`dataset.yaml`) file containing the path to the training and validation images and labels. This file will also contain the class names from the dataset.\n",
    "\n",
    "The dataset contains 16 classes.\n",
    "\n",
    "The following block shows the contents of the `dataset.yaml` file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "names:\n",
    "- AllenKey\n",
    "- Axis2\n",
    "- Bearing2\n",
    "- Drill\n",
    "- F20_20_B\n",
    "- F20_20_G\n",
    "- Housing\n",
    "- M20\n",
    "- M20_100\n",
    "- M30\n",
    "- Motor2\n",
    "- S40_40_B\n",
    "- S40_40_G\n",
    "- Screwdriver\n",
    "- Spacer\n",
    "- Wrench\n",
    "nc: 16\n",
    "train: train/images\n",
    "val: val/images\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a Few Ground Truth Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In YOLO format, [x_center, y_center, width, height]\n",
    "\n",
    "\n",
    "```\n",
    "A------------------------\n",
    "-------------------------\n",
    "-------------------------\n",
    "-------------------------\n",
    "-------------------------\n",
    "------------------------B\n",
    "```\n",
    "\n",
    "In Bounding Box format, A [x_min, y_min] and B [x_max, y_max].\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize 4 random samples from Dataset [Reference](https://www.youtube.com/watch?v=Ciy1J97dbY0&ab_channel=LearnOpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.yaml file\n",
    "data_yaml = \"/home/kpatel2s/kpatel2s/b_it_bots/2d_object_detection/yolo-object-detection/datasets/robocup_2023_dataset/dataset.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the dataset.yaml file exists\n",
    "if not os.path.exists(data_yaml):\n",
    "    print(\"dataset.yaml file does not exist. Please check the path.\")\n",
    "    exit()\n",
    "\n",
    "# load the dataset.yaml file\n",
    "with open(data_yaml, 'r') as stream:\n",
    "    data_yaml_dict = yaml.safe_load(stream)\n",
    "\n",
    "# class names\n",
    "class_names = data_yaml_dict['names']\n",
    "print(\"Class names: \", class_names)\n",
    "colors = np.random.uniform(0, 255, size=(len(class_names), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\n",
    "def yolo2bbox(bboxes):\n",
    "    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n",
    "    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n",
    "    return xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(image, bboxes, labels):\n",
    "    # Need the image height and width to denormalize\n",
    "    # the bounding box coordinates\n",
    "    h, w, _ = image.shape\n",
    "    for box_num, box in enumerate(bboxes):\n",
    "        x1, y1, x2, y2 = yolo2bbox(box)\n",
    "        # denormalize the coordinates\n",
    "        xmin = int(x1*w)\n",
    "        ymin = int(y1*h)\n",
    "        xmax = int(x2*w)\n",
    "        ymax = int(y2*h)\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "\n",
    "        class_name = class_names[int(labels[box_num])]\n",
    "\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (xmin, ymin), (xmax, ymax),\n",
    "            color=colors[class_names.index(class_name)],\n",
    "            thickness=2\n",
    "        )\n",
    "\n",
    "        font_scale = min(0.7, max(1, int(w/500)))\n",
    "        font_thickness = min(2, max(10, int(w/50)))\n",
    "\n",
    "        p1, p2 = (int(xmin), int(ymin)), (int(xmax), int(ymax))\n",
    "        # Text width and height\n",
    "        tw, th = cv2.getTextSize(\n",
    "            class_name,\n",
    "            0, fontScale=font_scale, thickness=font_thickness\n",
    "        )[0]\n",
    "        p2 = p1[0] + tw, p1[1] + -th - 10\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            p1, p2,\n",
    "            color=colors[class_names.index(class_name)],\n",
    "            thickness=-1,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            class_name,\n",
    "            (xmin+1, ymin-10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.7,\n",
    "            (255, 255, 255),\n",
    "            font_thickness\n",
    "        )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot images with the bounding boxes.\n",
    "def plot(image_paths, label_paths, num_samples):\n",
    "    # Get files at image_paths and label_paths\n",
    "    all_training_images = glob.glob(image_paths)\n",
    "    all_training_labels = glob.glob(label_paths)\n",
    "    \n",
    "    # all_training_images = glob.glob(image_paths)\n",
    "    # all_training_labels = glob.glob(label_paths)\n",
    "    all_training_images.sort()\n",
    "    all_training_labels.sort()\n",
    "\n",
    "    num_images = len(all_training_images)\n",
    "\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i in range(num_samples):\n",
    "        j = random.randint(0, num_images-1)\n",
    "        # j = 0\n",
    "        image = cv2.imread(all_training_images[j])\n",
    "        with open(all_training_labels[j], 'r') as f:\n",
    "            bboxes = []\n",
    "            labels = []\n",
    "            label_lines = f.readlines()\n",
    "            for label_line in label_lines:\n",
    "                label = label_line.split(' ')[0]\n",
    "                bbox_string = label_line.split(' ')[1:]\n",
    "                x_c, y_c, w, h = bbox_string\n",
    "                x_c = float(x_c)\n",
    "                y_c = float(y_c)\n",
    "                w = float(w)\n",
    "                h = float(h.split('\\n')[0])\n",
    "                bboxes.append([x_c, y_c, w, h])\n",
    "                labels.append(label)\n",
    "        result_image = plot_box(image, bboxes, labels)\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(result_image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few training images.\n",
    "plot(\n",
    "    image_paths=os.path.join(os.path.dirname(data_yaml), data_yaml_dict['train'], '*'),\n",
    "    label_paths=os.path.join(os.path.dirname(data_yaml), data_yaml_dict['train'].replace('images', 'labels'), '*'),\n",
    "    num_samples=4,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs and Hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "pretrained_model = '/home/kpatel2s/kpatel2s/b_it_bots/2d_object_detection/yolo-object-detection/yolov8/yolov8_robocup_2023/yolov8s_308_461_epoch1000/weights/best.pt' # default is yolov8n.pt\n",
    "config_file = \"/home/kpatel2s/kpatel2s/b_it_bots/2d_object_detection/yolo-object-detection/yolov8/config/yolov8_config_robocup_2023.yaml\"\n",
    "data_yaml = \"/home/kpatel2s/kpatel2s/b_it_bots/2d_object_detection/yolo-object-detection/datasets/robocup_2023_dataset/dataset.yaml\"\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 2000\n",
    "image_size = 640\n",
    "batch_size = 128 # (-1 for AutoBatch, works only for single GPU)\n",
    "project_name = \"yolov8_robocup_2023/train\" # save training results to <project-name>/train\n",
    "file_name = os.path.basename(os.path.splitext(pretrained_model)[0])\n",
    "model_name = f\"{file_name}_epoch{epochs}_\" if file_name != 'best' else f\"{pretrained_model.split('/')[-3]}_epoch{epochs}_\"\n",
    "cuda_devices = '0' # GPU devices ids \n",
    "freeze_layers = 10 # number of layers to freeze (from the beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layer(trainer):\n",
    "    model = trainer.model\n",
    "    num_freeze = freeze_layers\n",
    "    print(f\"Freezing {num_freeze} layers\")\n",
    "    freeze = [f'model.{x}.' for x in range(num_freeze)]  # layers to freeze \n",
    "    for k, v in model.named_parameters(): \n",
    "        v.requires_grad = True  # train all layers \n",
    "        if any(x in k for x in freeze): \n",
    "            print(f'freezing {k}') \n",
    "            v.requires_grad = False \n",
    "    print(f\"{num_freeze} layers are freezed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(pretrained_model)  # load a pretrained model (recommended for training)\n",
    "# model.add_callback(\"on_train_start\", freeze_layer) # DOESN\"T IMPROVE PERFORMANCE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcJVi6Imdf9b",
    "outputId": "2a062772-3414-4d6f-cc00-a4aab3012c29"
   },
   "outputs": [],
   "source": [
    "# Train a model using custom config yaml file\n",
    "model.train(cfg=config_file, # custom config file\n",
    "            data=data_yaml,\n",
    "            epochs=epochs,\n",
    "            imgsz=image_size,\n",
    "            batch=batch_size,\n",
    "            project=project_name,\n",
    "            name=model_name,\n",
    "            device=cuda_devices,\n",
    "            pretrained=True,\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: To free up GPU memory, follow these steps:https://askubuntu.com/a/1118325/922137"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor Model on TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir <path-to-result-directory> --port 6007"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wwfG5GQwqYoM"
   },
   "source": [
    "## Validation and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # if project_name:\n",
    "    dir_count = len(glob.glob(project_name + '/' + model_name + '*'))\n",
    "    if dir_count == 1:\n",
    "        RESULT_DIR = project_name + \"/\" + model_name\n",
    "    else:\n",
    "        RESULT_DIR = project_name + \"/\" + model_name + str(dir_count)\n",
    "    \n",
    "    without_training = False\n",
    "except Exception as e:\n",
    "    # else:\n",
    "    #### USER INPUT ####\n",
    "    # if running it without training, give a result directory name where the training results are saved.\n",
    "    RESULT_DIR = \"/home/kpatel2s/kpatel2s/b_it_bots/2d_object_detection/yolo-object-detection/yolov8/yolov8_robocup_2023/train/yolov8s_308_461_epoch1000_epoch3000_3\"\n",
    "\n",
    "    pretrained_model = os.path.join(RESULT_DIR, 'weights', 'best.pt')\n",
    "\n",
    "    # Load a model\n",
    "    model = YOLO(pretrained_model)  # load a pretrained model (recommended for training)\n",
    "\n",
    "    without_training = True\n",
    "\n",
    "RESULT_DIR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SyrImEH2qcN1"
   },
   "source": [
    "### Inference Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEKKeFxpqfMs"
   },
   "outputs": [],
   "source": [
    "# Function to show validation predictions saved during training.\n",
    "def show_valid_results(RES_DIR):\n",
    "    EXP_PATH = f\"{RES_DIR}\"\n",
    "    validation_pred_images = glob.glob(f\"{EXP_PATH}/*_pred.jpg\")\n",
    "    if len(validation_pred_images) == 0:\n",
    "        print(\"No validation predictions found.\")\n",
    "        return\n",
    "    for pred_image in validation_pred_images:\n",
    "        image = cv2.imread(pred_image)\n",
    "        plt.figure(figsize=(19, 16))\n",
    "        plt.imshow(image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QAF0wDI3qhJJ"
   },
   "source": [
    "The following functions are for carrying out inference on images/videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uy4VOSz0qifJ"
   },
   "outputs": [],
   "source": [
    "# Helper function for inference on images.\n",
    "def inference(RES_DIR, data_path, without_training=False):\n",
    "    # check data_path\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Data path {data_path} doesn't exist.\")\n",
    "        return\n",
    "    # Inference on images.\n",
    "    image_size = 640\n",
    "    confidence_threshold = 0.45\n",
    "    iou_threshold = 0.45\n",
    "    half_precision = True # use FP16 half-precision inference (faster, less accurate)\n",
    "    if without_training:\n",
    "        project_name = f\"{('/').join(RES_DIR.split('/')[:-2])}/predictions\"\n",
    "        model_name = f\"{RES_DIR.split('/')[-1]}_inference\"\n",
    "    else:\n",
    "        project_name = f\"{RES_DIR.split('/')[0]}/predictions\" # save inference results to <project-name>/predictions\n",
    "        model_name = f\"{RES_DIR.split('/')[2]}_inference\"\n",
    "    cuda_devices = '0' # GPU devices ids\n",
    "\n",
    "    # Prediction on test images\n",
    "    model.predict(source=data_path,\n",
    "                conf=confidence_threshold,\n",
    "                iou=iou_threshold,\n",
    "                half=half_precision,\n",
    "                device=cuda_devices,\n",
    "                save=True,\n",
    "                project=project_name,\n",
    "                name=model_name)\n",
    "    \n",
    "    dir_count = len(glob.glob(project_name+'/' + model_name + '*'))\n",
    "    if dir_count == 1:\n",
    "        INFER_DIR = project_name + \"/\" + model_name\n",
    "    else:\n",
    "        INFER_DIR = project_name + \"/\" + model_name + str(dir_count)\n",
    "    \n",
    "    return INFER_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-j53ehiqmZU"
   },
   "outputs": [],
   "source": [
    "def visualize(INFER_DIR):\n",
    "    # Visualize inference images.\n",
    "    INFER_PATH = f\"{INFER_DIR}\"\n",
    "    infer_images = glob.glob(f\"{INFER_PATH}/*\")\n",
    "    for pred_image in infer_images:\n",
    "        image = cv2.imread(pred_image)\n",
    "        plt.figure(figsize=(19, 16))\n",
    "        plt.imshow(image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UtKTNNDoqqi3"
   },
   "source": [
    "#### Visualize validation prediction images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "p_punILPqqWp",
    "outputId": "aeb5a1c2-f00c-4eee-f3ae-e7e82133aaba"
   },
   "outputs": [],
   "source": [
    "show_valid_results(RESULT_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jurecthtqvj9"
   },
   "source": [
    "### Inference\n",
    "In this section, we will carry out inference on unseen images. \n",
    "\n",
    "The images for inference are in the `test_images_robocup_2023` directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RTigK5v4q27c"
   },
   "source": [
    "**To carry out inference on images, we just need to provide the directory path where all the images are stored, and inference will happen on all images automatically.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0k-GZGFq4IS",
    "outputId": "5456023a-da3f-460e-bf0a-6c396d4d2928"
   },
   "outputs": [],
   "source": [
    "on_single_image = False\n",
    "\n",
    "if on_single_image:\n",
    "    # Inference on single image\n",
    "    IMAGE_INFER_DIR = inference(RESULT_DIR, '/home/kpatel2s/kpatel2s/b_it_bots/2d_object_detection/yolo-object-detection/datasets/test_images_robocup_2023/set2_frame00000.png', without_training)\n",
    "else:\n",
    "    # Inference on images.\n",
    "    IMAGE_INFER_DIR = inference(RESULT_DIR, '/home/kpatel2s/kpatel2s/b_it_bots/2d_object_detection/yolo-object-detection/datasets/test_images_robocup_2023', without_training)\n",
    "\n",
    "IMAGE_INFER_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JLDCTeBfq5jO",
    "outputId": "13fa46d6-fbaa-401e-e7cc-14c82b4e3b6b"
   },
   "outputs": [],
   "source": [
    "# IMAGE_INFER_DIR\n",
    "visualize(IMAGE_INFER_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model (.pt) to ONNX model (.onnx)\n",
    "##### Reference: https://docs.ultralytics.com/modes/export/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model to ONNX\n",
    "path = model.export(format=\"onnx\", opset=12)\n",
    "print(\"Exported model to: \", path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "custom_object_detection_using_YOLOv5_opencv.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
