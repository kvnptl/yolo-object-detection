{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2yQrsczCsGc"
   },
   "source": [
    "Reference: [Ultralytics YoloV5 github repository](https://github.com/ultralytics/yolov5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ggh0QkBkC-nl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob as glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import requests #to download some data from internet\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnZk1ICNDy-v",
    "outputId": "1fb93a0d-6264-4090-ab51-04851afdbc25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/public/b_it_bot_work/2d_perception\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnz28UfVEIc0"
   },
   "source": [
    "## Prepare the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxXS00JRI2fQ"
   },
   "source": [
    "Dataset for Summer 2022 competition Source: [HBRS Bib cloud](https://bib-cloud.bib.hochschule-bonn-rhein-sieg.de/apps/files/?dir=/Shared/b-it-bots-ds/atwork/images/object_detection/YOLO/internal_robocup_2022/FULL_DATASET_SS22_COMPETITION&fileid=14231157)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xmzv2t5I4kh"
   },
   "source": [
    "The dataset is structured in the following manner:\n",
    "\n",
    "```\n",
    "├── dataset_ss22_v4.yaml\n",
    "├── README.md\n",
    "├── dataset_ss22_v4\n",
    "        train\n",
    "        ├── images\n",
    "        └── labels\n",
    "        valid\n",
    "        ├── images\n",
    "        └── labels\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9hbCfxlZ05u"
   },
   "source": [
    "### The Dataset YAML File\n",
    "\n",
    "The dataset YAML (`dataset_ss22_v4.yaml`) file containing the path to the training and validation images and labels. This file will also contain the class names from the dataset.\n",
    "\n",
    "The dataset contains 20 classes.\n",
    "\n",
    "The following block shows the contents of the `dataset_ss22_v4.yaml` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcdcMP3oZ_cy"
   },
   "source": [
    "```yaml\n",
    "train: ../dataset_ss22_v4/train/images\n",
    "val: ../dataset_ss22_v4/valid/images\n",
    "\n",
    "nc: 20\n",
    "\n",
    "names: ['F20_20_B', 'R20', 'S40_40_B', 'S40_40_G', 'axis', 'bearing_box', 'bracket', 'brown_box', 'cup', 'dishwasher_soap', 'eye_glasses', 'insulation_tape', 'motor', 'pringles', 'screw_driver', 'sponge', 'spoon', 'tennis_ball', 'toothbrush', 'towel']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4Lo0u6LaBss"
   },
   "source": [
    "### Visualize a Few Ground Truth Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q602BrX1advP"
   },
   "source": [
    "In YOLO format, [x_center, y_center, width, height]\n",
    "\n",
    "\n",
    "```\n",
    "A------------------------\n",
    "-------------------------\n",
    "-------------------------\n",
    "-------------------------\n",
    "-------------------------\n",
    "------------------------B\n",
    "```\n",
    "\n",
    "In Bounding Box format, A [x_min, y_min] and B [x_max, y_max].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize 4 random samples from Dataset\n",
    "\n",
    "[Reference](https://www.youtube.com/watch?v=Ciy1J97dbY0&ab_channel=LearnOpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GXzvoHfnZ1p_"
   },
   "outputs": [],
   "source": [
    "class_names = ['F20_20_B', 'R20', 'S40_40_B', 'S40_40_G', 'axis', 'bearing_box', 'bracket', 'brown_box', 'cup', \n",
    "               'dishwasher_soap', 'eye_glasses', 'insulation_tape', 'motor', 'pringles', 'screw_driver', 'sponge', \n",
    "               'spoon', 'tennis_ball', 'toothbrush', 'towel']\n",
    "colors = np.random.uniform(0, 255, size=(len(class_names), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\n",
    "def yolo2bbox(bboxes):\n",
    "    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n",
    "    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n",
    "    return xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqk-XxiPbUSb"
   },
   "outputs": [],
   "source": [
    "def plot_box(image, bboxes, labels):\n",
    "    # Need the image height and width to denormalize\n",
    "    # the bounding box coordinates\n",
    "    h, w, _ = image.shape\n",
    "    for box_num, box in enumerate(bboxes):\n",
    "        x1, y1, x2, y2 = yolo2bbox(box)\n",
    "        # denormalize the coordinates\n",
    "        xmin = int(x1*w)\n",
    "        ymin = int(y1*h)\n",
    "        xmax = int(x2*w)\n",
    "        ymax = int(y2*h)\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "\n",
    "        class_name = class_names[int(labels[box_num])]\n",
    "\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (xmin, ymin), (xmax, ymax),\n",
    "            color=colors[class_names.index(class_name)],\n",
    "            thickness=2\n",
    "        )\n",
    "\n",
    "        font_scale = min(1, max(3, int(w/500)))\n",
    "        font_thickness = min(2, max(10, int(w/50)))\n",
    "\n",
    "        p1, p2 = (int(xmin), int(ymin)), (int(xmax), int(ymax))\n",
    "        # Text width and height\n",
    "        tw, th = cv2.getTextSize(\n",
    "            class_name,\n",
    "            0, fontScale=font_scale, thickness=font_thickness\n",
    "        )[0]\n",
    "        p2 = p1[0] + tw, p1[1] + -th - 10\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            p1, p2,\n",
    "            color=colors[class_names.index(class_name)],\n",
    "            thickness=-1,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            class_name,\n",
    "            (xmin+1, ymin-10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            font_scale,\n",
    "            (255, 255, 255),\n",
    "            font_thickness\n",
    "        )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tt_M-eQWb2VC"
   },
   "outputs": [],
   "source": [
    "# Function to plot images with the bounding boxes.\n",
    "def plot(image_paths, label_paths, num_samples):\n",
    "    all_training_images = glob.glob(image_paths)\n",
    "    all_training_labels = glob.glob(label_paths)\n",
    "    all_training_images.sort()\n",
    "    all_training_labels.sort()\n",
    "\n",
    "    num_images = len(all_training_images)\n",
    "\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i in range(num_samples):\n",
    "        j = random.randint(0, num_images-1)\n",
    "        # j = 0\n",
    "        image = cv2.imread(all_training_images[j])\n",
    "        with open(all_training_labels[j], 'r') as f:\n",
    "            bboxes = []\n",
    "            labels = []\n",
    "            label_lines = f.readlines()\n",
    "            for label_line in label_lines:\n",
    "                label = label_line.split(' ')[0]\n",
    "                bbox_string = label_line.split(' ')[1:]\n",
    "                x_c, y_c, w, h = bbox_string\n",
    "                x_c = float(x_c)\n",
    "                y_c = float(y_c)\n",
    "                w = float(w)\n",
    "                h = float(h.split('\\n')[0])\n",
    "                bboxes.append([x_c, y_c, w, h])\n",
    "                labels.append(label)\n",
    "        result_image = plot_box(image, bboxes, labels)\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(result_image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 873
    },
    "id": "-rBlnGadcABY",
    "outputId": "61070f83-7d9f-45f8-9cce-ea726db8f21c"
   },
   "outputs": [],
   "source": [
    "# Visualize a few training images.\n",
    "plot(\n",
    "    image_paths='dataset_ss22_v4/train/images/*', \n",
    "    label_paths='dataset_ss22_v4/train/labels/*',\n",
    "    num_samples=4,\n",
    ")\n",
    "\n",
    "# plot(\n",
    "#     image_paths='dataset_ss22_inference/train/images/*', \n",
    "#     label_paths='dataset_ss22_inference/train/labels/*',\n",
    "#     num_samples=4,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pc7jxboMczbd"
   },
   "source": [
    "## Helper Functions for Logging\n",
    "\n",
    "The helper functions are for logging of the results in the notebook while training the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "L7t1wctqcoN-"
   },
   "outputs": [],
   "source": [
    "def set_res_dir():\n",
    "    # Directory to store results\n",
    "    #res_dir_count = len(glob.glob('runs/train/*'))\n",
    "    res_dir_count = len(glob.glob('/home/jovyan/public/logs/yolo5/train/*'))\n",
    "    print(f\"Current number of result directories: {res_dir_count}\")\n",
    "    if TRAIN:\n",
    "        RES_DIR = f\"/home/jovyan/public/logs/yolo5/train/results_{res_dir_count+1}\"\n",
    "        print(RES_DIR)\n",
    "    else:\n",
    "        RES_DIR = f\"/home/jovyan/public/logs/yolo5/train/results_{res_dir_count}\"\n",
    "    return RES_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDkUcgESddUY"
   },
   "source": [
    "## Clone YOLOV5 Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mlIqGP_7dZAp"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('yolov5'):\n",
    "    !git clone https://github.com/ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcJVi6Imdf9b",
    "outputId": "2a062772-3414-4d6f-cc00-a4aab3012c29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/public/b_it_bot_work/2d_perception/yolov5\n"
     ]
    }
   ],
   "source": [
    "# Change to yoloV5 directory\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function to Monitor TensorBoard logs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LSPPYL7dI6u"
   },
   "source": [
    "**NOTE**: TensorBoard logs can be visualized with [Local port link](http://10.20.118.78:31025/#scalars&runSelectionState=eyJ5b2xvNS90cmFpbi9yZXN1bHRzXzEiOmZhbHNlLCJ5b2xvNS90cmFpbi9yZXN1bHRzXzIiOmZhbHNlLCJ5b2xvNS90cmFpbi9yZXN1bHRzXzMiOmZhbHNlLCJ5b2xvNS90cmFpbi9yZXN1bHRzXzQiOmZhbHNlLCJ5b2xvNS90cmFpbi9yZXN1bHRzXzUiOmZhbHNlLCJ5b2xvNS90cmFpbi9yZXN1bHRzXzgiOmZhbHNlLCJ5b2xvNS90cmFpbi9yZXN1bHRzXzgyIjpmYWxzZSwieW9sbzUvdHJhaW4vcmVzdWx0c18xNCI6ZmFsc2UsInlvbG81L3RyYWluL3Jlc3VsdHNfMTMiOmZhbHNlLCJ5b2xvNS90cmFpbi9yZXN1bHRzXzEyIjpmYWxzZSwieW9sbzUvdHJhaW4vcmVzdWx0c18xMSI6ZmFsc2V9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5tNBYgud4df"
   },
   "source": [
    "## Training using YOLOV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QFXnIfvzDz11"
   },
   "outputs": [],
   "source": [
    "TRAIN = True\n",
    "FREEZE = True # freezing first 15 layers\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If already trained model (.pt file) is available, then give that model path in `--weights` argument\n",
    "Note: User configurable arguments\n",
    "- batch size\n",
    "- data yaml path\n",
    "- pre-trained weight file\n",
    "- image size\n",
    "- epochs\n",
    "- result directory\n",
    "- freeze layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TiGPfG7exH9",
    "outputId": "794e63de-4fa3-430b-c181-89ab7349e92b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of result directories: 68\n",
      "/home/jovyan/public/logs/yolo5/train/results_69\n",
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=../dataset_ss22_v4.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1000, batch_size=512, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0,1, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=/home/jovyan/public/logs/yolo5/train/results_69, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 167 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"thop>=0.1.1\" not found, attempting AutoUpdate...\n",
      "Collecting thop>=0.1.1\n",
      "  Using cached thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from thop>=0.1.1) (1.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->thop>=0.1.1) (4.4.0)\n",
      "Installing collected packages: thop\n",
      "Successfully installed thop-0.1.1.post2209072238\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /home/jovyan/public/b_it_bot_work/2d_perception/yolov5/requirements.txt\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "YOLOv5 🚀 2022-11-9 Python-3.10.9 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24268MiB)\n",
      "                                                     CUDA:1 (NVIDIA GeForce RTX 3090, 24265MiB)\n",
      "\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /home/jovyan/public/logs/yolo5/train', view at http://localhost:6006/\n",
      "2023-04-13 15:29:37.165160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-13 15:29:38.397817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:/opt/conda/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-13 15:29:38.397903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:/opt/conda/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-13 15:29:38.397913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Overriding model.yaml nc=80 with nc=20\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1    101025  models.yolo.Detect                      [20, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20948097 parameters, 20948097 gradients\n",
      "\n",
      "Transferred 475/481 items from yolov5m.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "freezing model.0.conv.weight\n",
      "freezing model.0.bn.weight\n",
      "freezing model.0.bn.bias\n",
      "freezing model.1.conv.weight\n",
      "freezing model.1.bn.weight\n",
      "freezing model.1.bn.bias\n",
      "freezing model.2.cv1.conv.weight\n",
      "freezing model.2.cv1.bn.weight\n",
      "freezing model.2.cv1.bn.bias\n",
      "freezing model.2.cv2.conv.weight\n",
      "freezing model.2.cv2.bn.weight\n",
      "freezing model.2.cv2.bn.bias\n",
      "freezing model.2.cv3.conv.weight\n",
      "freezing model.2.cv3.bn.weight\n",
      "freezing model.2.cv3.bn.bias\n",
      "freezing model.2.m.0.cv1.conv.weight\n",
      "freezing model.2.m.0.cv1.bn.weight\n",
      "freezing model.2.m.0.cv1.bn.bias\n",
      "freezing model.2.m.0.cv2.conv.weight\n",
      "freezing model.2.m.0.cv2.bn.weight\n",
      "freezing model.2.m.0.cv2.bn.bias\n",
      "freezing model.2.m.1.cv1.conv.weight\n",
      "freezing model.2.m.1.cv1.bn.weight\n",
      "freezing model.2.m.1.cv1.bn.bias\n",
      "freezing model.2.m.1.cv2.conv.weight\n",
      "freezing model.2.m.1.cv2.bn.weight\n",
      "freezing model.2.m.1.cv2.bn.bias\n",
      "freezing model.3.conv.weight\n",
      "freezing model.3.bn.weight\n",
      "freezing model.3.bn.bias\n",
      "freezing model.4.cv1.conv.weight\n",
      "freezing model.4.cv1.bn.weight\n",
      "freezing model.4.cv1.bn.bias\n",
      "freezing model.4.cv2.conv.weight\n",
      "freezing model.4.cv2.bn.weight\n",
      "freezing model.4.cv2.bn.bias\n",
      "freezing model.4.cv3.conv.weight\n",
      "freezing model.4.cv3.bn.weight\n",
      "freezing model.4.cv3.bn.bias\n",
      "freezing model.4.m.0.cv1.conv.weight\n",
      "freezing model.4.m.0.cv1.bn.weight\n",
      "freezing model.4.m.0.cv1.bn.bias\n",
      "freezing model.4.m.0.cv2.conv.weight\n",
      "freezing model.4.m.0.cv2.bn.weight\n",
      "freezing model.4.m.0.cv2.bn.bias\n",
      "freezing model.4.m.1.cv1.conv.weight\n",
      "freezing model.4.m.1.cv1.bn.weight\n",
      "freezing model.4.m.1.cv1.bn.bias\n",
      "freezing model.4.m.1.cv2.conv.weight\n",
      "freezing model.4.m.1.cv2.bn.weight\n",
      "freezing model.4.m.1.cv2.bn.bias\n",
      "freezing model.4.m.2.cv1.conv.weight\n",
      "freezing model.4.m.2.cv1.bn.weight\n",
      "freezing model.4.m.2.cv1.bn.bias\n",
      "freezing model.4.m.2.cv2.conv.weight\n",
      "freezing model.4.m.2.cv2.bn.weight\n",
      "freezing model.4.m.2.cv2.bn.bias\n",
      "freezing model.4.m.3.cv1.conv.weight\n",
      "freezing model.4.m.3.cv1.bn.weight\n",
      "freezing model.4.m.3.cv1.bn.bias\n",
      "freezing model.4.m.3.cv2.conv.weight\n",
      "freezing model.4.m.3.cv2.bn.weight\n",
      "freezing model.4.m.3.cv2.bn.bias\n",
      "freezing model.5.conv.weight\n",
      "freezing model.5.bn.weight\n",
      "freezing model.5.bn.bias\n",
      "freezing model.6.cv1.conv.weight\n",
      "freezing model.6.cv1.bn.weight\n",
      "freezing model.6.cv1.bn.bias\n",
      "freezing model.6.cv2.conv.weight\n",
      "freezing model.6.cv2.bn.weight\n",
      "freezing model.6.cv2.bn.bias\n",
      "freezing model.6.cv3.conv.weight\n",
      "freezing model.6.cv3.bn.weight\n",
      "freezing model.6.cv3.bn.bias\n",
      "freezing model.6.m.0.cv1.conv.weight\n",
      "freezing model.6.m.0.cv1.bn.weight\n",
      "freezing model.6.m.0.cv1.bn.bias\n",
      "freezing model.6.m.0.cv2.conv.weight\n",
      "freezing model.6.m.0.cv2.bn.weight\n",
      "freezing model.6.m.0.cv2.bn.bias\n",
      "freezing model.6.m.1.cv1.conv.weight\n",
      "freezing model.6.m.1.cv1.bn.weight\n",
      "freezing model.6.m.1.cv1.bn.bias\n",
      "freezing model.6.m.1.cv2.conv.weight\n",
      "freezing model.6.m.1.cv2.bn.weight\n",
      "freezing model.6.m.1.cv2.bn.bias\n",
      "freezing model.6.m.2.cv1.conv.weight\n",
      "freezing model.6.m.2.cv1.bn.weight\n",
      "freezing model.6.m.2.cv1.bn.bias\n",
      "freezing model.6.m.2.cv2.conv.weight\n",
      "freezing model.6.m.2.cv2.bn.weight\n",
      "freezing model.6.m.2.cv2.bn.bias\n",
      "freezing model.6.m.3.cv1.conv.weight\n",
      "freezing model.6.m.3.cv1.bn.weight\n",
      "freezing model.6.m.3.cv1.bn.bias\n",
      "freezing model.6.m.3.cv2.conv.weight\n",
      "freezing model.6.m.3.cv2.bn.weight\n",
      "freezing model.6.m.3.cv2.bn.bias\n",
      "freezing model.6.m.4.cv1.conv.weight\n",
      "freezing model.6.m.4.cv1.bn.weight\n",
      "freezing model.6.m.4.cv1.bn.bias\n",
      "freezing model.6.m.4.cv2.conv.weight\n",
      "freezing model.6.m.4.cv2.bn.weight\n",
      "freezing model.6.m.4.cv2.bn.bias\n",
      "freezing model.6.m.5.cv1.conv.weight\n",
      "freezing model.6.m.5.cv1.bn.weight\n",
      "freezing model.6.m.5.cv1.bn.bias\n",
      "freezing model.6.m.5.cv2.conv.weight\n",
      "freezing model.6.m.5.cv2.bn.weight\n",
      "freezing model.6.m.5.cv2.bn.bias\n",
      "freezing model.7.conv.weight\n",
      "freezing model.7.bn.weight\n",
      "freezing model.7.bn.bias\n",
      "freezing model.8.cv1.conv.weight\n",
      "freezing model.8.cv1.bn.weight\n",
      "freezing model.8.cv1.bn.bias\n",
      "freezing model.8.cv2.conv.weight\n",
      "freezing model.8.cv2.bn.weight\n",
      "freezing model.8.cv2.bn.bias\n",
      "freezing model.8.cv3.conv.weight\n",
      "freezing model.8.cv3.bn.weight\n",
      "freezing model.8.cv3.bn.bias\n",
      "freezing model.8.m.0.cv1.conv.weight\n",
      "freezing model.8.m.0.cv1.bn.weight\n",
      "freezing model.8.m.0.cv1.bn.bias\n",
      "freezing model.8.m.0.cv2.conv.weight\n",
      "freezing model.8.m.0.cv2.bn.weight\n",
      "freezing model.8.m.0.cv2.bn.bias\n",
      "freezing model.8.m.1.cv1.conv.weight\n",
      "freezing model.8.m.1.cv1.bn.weight\n",
      "freezing model.8.m.1.cv1.bn.bias\n",
      "freezing model.8.m.1.cv2.conv.weight\n",
      "freezing model.8.m.1.cv2.bn.weight\n",
      "freezing model.8.m.1.cv2.bn.bias\n",
      "freezing model.9.cv1.conv.weight\n",
      "freezing model.9.cv1.bn.weight\n",
      "freezing model.9.cv1.bn.bias\n",
      "freezing model.9.cv2.conv.weight\n",
      "freezing model.9.cv2.bn.weight\n",
      "freezing model.9.cv2.bn.bias\n",
      "freezing model.10.conv.weight\n",
      "freezing model.10.bn.weight\n",
      "freezing model.10.bn.bias\n",
      "freezing model.13.cv1.conv.weight\n",
      "freezing model.13.cv1.bn.weight\n",
      "freezing model.13.cv1.bn.bias\n",
      "freezing model.13.cv2.conv.weight\n",
      "freezing model.13.cv2.bn.weight\n",
      "freezing model.13.cv2.bn.bias\n",
      "freezing model.13.cv3.conv.weight\n",
      "freezing model.13.cv3.bn.weight\n",
      "freezing model.13.cv3.bn.bias\n",
      "freezing model.13.m.0.cv1.conv.weight\n",
      "freezing model.13.m.0.cv1.bn.weight\n",
      "freezing model.13.m.0.cv1.bn.bias\n",
      "freezing model.13.m.0.cv2.conv.weight\n",
      "freezing model.13.m.0.cv2.bn.weight\n",
      "freezing model.13.m.0.cv2.bn.bias\n",
      "freezing model.13.m.1.cv1.conv.weight\n",
      "freezing model.13.m.1.cv1.bn.weight\n",
      "freezing model.13.m.1.cv1.bn.bias\n",
      "freezing model.13.m.1.cv2.conv.weight\n",
      "freezing model.13.m.1.cv2.bn.weight\n",
      "freezing model.13.m.1.cv2.bn.bias\n",
      "freezing model.14.conv.weight\n",
      "freezing model.14.bn.weight\n",
      "freezing model.14.bn.bias\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.004), 82 bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/jovyan/public/b_it_bot_work/2d_perception/dataset_ss22_v4\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/jovyan/public/b_it_bot_work/2d_perception/dataset_ss22_v4/v\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.48 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to /home/jovyan/public/logs/yolo5/train/results_69/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 16 dataloader workers\n",
      "Logging results to \u001b[1m/home/jovyan/public/logs/yolo5/train/results_69\u001b[0m\n",
      "Starting training for 1000 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/999      22.1G      0.118    0.05252    0.08134       1870        640:  Reducer buckets have been rebuilt in this iteration.\n",
      "      0/999      20.6G     0.1182    0.05368    0.08142        276        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575   0.000719     0.0478    0.00051   0.000122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/999      21.5G     0.1124    0.05398    0.08083        212        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575    0.00152      0.112     0.0014   0.000317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      2/999      21.6G    0.09873     0.0627       0.08        241        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575    0.00666      0.471    0.00913    0.00237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      3/999      21.6G    0.08461    0.06187    0.07862        176        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575    0.00907      0.601     0.0146    0.00414\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      4/999      21.6G    0.07737    0.06374     0.0773        230        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575     0.0412      0.135     0.0336    0.00847\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      5/999      21.6G    0.07264    0.06128    0.07662        225        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575     0.0372      0.148       0.03    0.00971\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      6/999      21.6G     0.0679    0.05718     0.0761        194        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575     0.0312      0.197     0.0349     0.0124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      7/999      21.6G    0.06348     0.0551    0.07586        217        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575     0.0349      0.189     0.0446     0.0171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      8/999      21.6G    0.06026     0.0572      0.075        268        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575     0.0611      0.217     0.0668     0.0265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      9/999      21.6G    0.05833    0.05718    0.07432        310        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575     0.0754      0.194     0.0841     0.0328\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     10/999      21.6G    0.05844    0.04959    0.07353        224        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575     0.0917      0.195     0.0972     0.0366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     11/999      21.6G    0.05665     0.0506    0.07325        245        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.109      0.229      0.115     0.0447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     12/999      21.6G    0.05607    0.05123    0.07256        263        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.126      0.215      0.124      0.054\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     13/999      21.6G     0.0542    0.05047    0.07193        241        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.144      0.219      0.145     0.0654\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     14/999      21.6G     0.0566    0.04802    0.07119        204        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.166       0.21      0.153     0.0676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     15/999      21.6G    0.05341    0.04764    0.07075        222        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.182      0.242      0.179     0.0836\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     16/999      21.6G    0.05096    0.04646    0.06999        215        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.169       0.24      0.151      0.067\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     17/999      21.6G    0.05302    0.04554    0.06922        201        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.164      0.235      0.177     0.0764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     18/999      21.6G    0.05015    0.04657    0.06861        222        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.182      0.264      0.196     0.0857\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     19/999      21.6G    0.05112    0.04683    0.06807        240        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.191      0.224      0.195      0.089\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     20/999      21.6G    0.05072    0.04443    0.06724        193        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.194       0.28      0.212     0.0969\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     21/999      21.6G    0.04901    0.04408    0.06639        229        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.175      0.329      0.194     0.0823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     22/999      21.6G    0.04793    0.04233    0.06503        180        640: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.215      0.359      0.224      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     23/999      21.6G    0.04759    0.04538    0.06396        251        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.222      0.356      0.257      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     24/999      21.6G    0.04718    0.03992    0.06239        174        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.214      0.406      0.242     0.0913\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     25/999      21.6G    0.04628    0.04285     0.0615        235        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.275      0.438      0.315       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     26/999      21.6G    0.04552      0.041    0.06008        211        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.277      0.442       0.32      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     27/999      21.6G    0.04284    0.04298    0.05811        237        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.29      0.469      0.338      0.169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     28/999      21.6G    0.04234    0.04071    0.05717        206        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.329      0.479      0.375      0.187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     29/999      21.6G    0.04168    0.03998    0.05619        185        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.372      0.506      0.427        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     30/999      21.6G    0.04219    0.03917    0.05436        204        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.434      0.523      0.481      0.273\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     31/999      21.6G    0.04072    0.03917    0.05366        210        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.466      0.529       0.51      0.273\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     32/999      21.6G    0.04029    0.03995    0.05166        232        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.495       0.55      0.541      0.284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     33/999      21.6G    0.03982    0.03908    0.05013        238        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.532       0.56      0.573      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     34/999      21.6G    0.03864    0.03914    0.04927        227        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.552      0.584      0.577      0.304\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     35/999      21.6G    0.03785    0.04004    0.04795        257        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.576      0.605      0.615       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     36/999      21.6G    0.03726    0.03878    0.04598        260        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.583      0.607      0.629      0.386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     37/999      21.6G    0.03767    0.03866    0.04569        236        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.612      0.607      0.639      0.386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     38/999      21.6G    0.03759     0.0373    0.04399        246        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.641      0.633      0.673      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     39/999      21.6G    0.03691    0.03542    0.04268        206        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.646      0.642      0.678      0.425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     40/999      21.6G    0.03628    0.03879    0.04205        255        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.663      0.672      0.711       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     41/999      21.6G    0.03594    0.03508    0.04059        207        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.685      0.672      0.722      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     42/999      21.6G    0.03585    0.03456    0.04028        190        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.69      0.692      0.727      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     43/999      21.6G    0.03541    0.03613    0.03835        225        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.642      0.714      0.719      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     44/999      21.6G    0.03526    0.03512    0.03703        237        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.716       0.74      0.774       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     45/999      21.6G    0.03505    0.03533    0.03628        212        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.731      0.742      0.783      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     46/999      21.6G    0.03512    0.03521    0.03437        227        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.732      0.765      0.802      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     47/999      21.6G    0.03453    0.03671    0.03372        258        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.772      0.764      0.807      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     48/999      21.6G    0.03448    0.03397    0.03386        206        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.793      0.769      0.825      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     49/999      21.6G    0.03408    0.03511    0.03302        211        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.764      0.773      0.817      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     50/999      21.6G    0.03359    0.03367    0.03082        224        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.815      0.782      0.849      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     51/999      21.6G    0.03406     0.0345    0.03065        246        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.81      0.791      0.855      0.583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     52/999      21.6G    0.03307    0.03369    0.03039        199        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.832      0.819       0.87      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     53/999      21.6G    0.03406     0.0332    0.02917        207        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.835       0.83      0.885       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     54/999      21.6G    0.03273    0.03396    0.02955        206        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.85      0.848       0.89      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     55/999      21.6G    0.03285    0.03191    0.02756        210        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.859      0.842      0.893      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     56/999      21.6G    0.03289    0.03264    0.02669        214        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.857      0.844      0.898      0.636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     57/999      21.6G    0.03301    0.03185    0.02722        170        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.842      0.845       0.89      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     58/999      21.6G    0.03287    0.03227    0.02595        194        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.85      0.872      0.911      0.641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     59/999      21.6G     0.0332    0.03295    0.02499        216        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.851      0.863      0.912      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     60/999      21.6G    0.03241    0.03301    0.02478        231        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.87      0.866      0.917      0.653\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     61/999      21.6G    0.03215    0.03125    0.02474        190        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.862      0.891       0.92      0.662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     62/999      21.6G    0.03149    0.03318    0.02416        235        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.876      0.902      0.929      0.659\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     63/999      21.6G    0.03231    0.03293    0.02271        229        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.888      0.891      0.933      0.674\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     64/999      21.6G    0.03096    0.03297    0.02258        264        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.881      0.912      0.939       0.65\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     65/999      21.6G    0.03142    0.03216    0.02244        222        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.891      0.883      0.935       0.68\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     66/999      21.6G    0.03176     0.0319    0.02202        221        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.894      0.889      0.934      0.664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     67/999      21.6G    0.03053    0.03199    0.02106        231        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.909      0.908      0.944      0.698\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     68/999      21.6G    0.03161    0.03126    0.02073        220        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.916      0.901      0.942        0.7\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     69/999      21.6G    0.03096    0.03046    0.01996        190        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.921       0.89      0.945      0.683\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     70/999      21.6G    0.03097    0.02971     0.0206        188        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.904      0.908      0.942      0.684\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     71/999      21.6G    0.03048    0.03151    0.02008        236        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.902      0.896      0.939      0.681\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     72/999      21.6G    0.03178    0.03181    0.01901        215        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.908      0.913      0.949      0.693\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     73/999      21.6G    0.03104    0.03118    0.01838        219        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.901      0.873      0.929      0.669\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     74/999      21.6G    0.03005    0.03036    0.01871        230        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.908      0.918      0.949        0.7\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     75/999      21.6G    0.03006    0.03067    0.01824        231        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.915      0.921       0.95      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     76/999      21.6G    0.03028    0.03179    0.01848        210        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.923      0.887      0.945      0.718\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     77/999      21.6G    0.03057    0.03205    0.01823        209        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.914      0.916       0.95      0.708\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     78/999      21.6G    0.03051    0.02901    0.01764        191        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.933       0.92      0.957      0.712\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     79/999      21.6G    0.03028    0.03047    0.01776        226        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.93      0.924      0.962      0.734\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     80/999      21.6G    0.02977    0.03033    0.01745        215        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.934      0.925      0.964      0.711\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     81/999      21.6G    0.02992    0.03024    0.01691        227        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.938      0.935      0.969      0.709\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     82/999      21.6G    0.02978    0.03091    0.01642        235        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.945      0.935      0.971      0.738\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     83/999      21.6G    0.02989    0.03188    0.01668        244        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.937      0.917      0.962      0.721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     84/999      21.6G    0.02928    0.03158    0.01574        282        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.925      0.933      0.968      0.741\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     85/999      21.6G    0.02939    0.02924    0.01619        203        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.946      0.935      0.969      0.712\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     86/999      21.6G    0.02994    0.02912    0.01573        186        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.945       0.93      0.969      0.722\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     87/999      21.6G    0.02987    0.02899    0.01609        185        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.949      0.945      0.972       0.73\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     88/999      21.6G    0.02894    0.03097    0.01523        238        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.956      0.948      0.975      0.727\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     89/999      21.6G     0.0292    0.03003    0.01546        219        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.95      0.931      0.972      0.735\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     90/999      21.6G    0.02855    0.03095    0.01506        260        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.951      0.944      0.971       0.74\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     91/999      21.6G    0.02908    0.03103    0.01551        202        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.956      0.953      0.979      0.742\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     92/999      21.6G    0.02882    0.03031    0.01488        231        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.972      0.952      0.982      0.742\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     93/999      21.6G     0.0299    0.02969    0.01512        235        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.973      0.949       0.98      0.753\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     94/999      21.6G    0.02819    0.02999    0.01424        261        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.959      0.957       0.98      0.753\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     95/999      21.6G    0.02903    0.02949    0.01445        191        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.956      0.956       0.98      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     96/999      21.6G    0.02957    0.02986    0.01443        196        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.968      0.961      0.983      0.756\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     97/999      21.6G    0.02867    0.02754    0.01394        174        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.968      0.957       0.98      0.744\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     98/999      21.6G    0.02823    0.02972    0.01341        235        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.962      0.954      0.981       0.75\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     99/999      21.6G    0.02879    0.02859    0.01325        194        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.963      0.952       0.98      0.758\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    100/999      21.6G    0.02859    0.02799    0.01397        181        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.968      0.948      0.982      0.767\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    101/999      21.6G    0.02827    0.02923    0.01307        236        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.963       0.95      0.981      0.768\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    102/999      21.6G    0.02813    0.02814     0.0133        220        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.973      0.936       0.98      0.759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    103/999      21.6G    0.02831    0.02947    0.01377        206        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.97      0.944      0.981      0.755\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    104/999      21.6G    0.02783    0.02972    0.01339        213        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.968      0.968      0.987       0.76\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    105/999      21.6G     0.0287    0.02911    0.01299        203        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.959      0.947      0.983      0.771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    106/999      21.6G    0.02814    0.02844    0.01187        212        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.971      0.952      0.984      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    107/999      21.6G    0.02825     0.0293    0.01253        222        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.966      0.961      0.984       0.77\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    108/999      21.6G     0.0285    0.02885    0.01245        204        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.964      0.959      0.984      0.763\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    109/999      21.6G    0.02748    0.02897    0.01191        218        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.981      0.964      0.988      0.768\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    110/999      21.6G    0.02816    0.02806    0.01159        219        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.969      0.968      0.987      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    111/999      21.6G    0.02857    0.02955    0.01202        240        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.975      0.968      0.988      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    112/999      21.6G    0.02693    0.02856    0.01123        233        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.968      0.964      0.986      0.761\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    113/999      21.6G    0.02732     0.0295     0.0118        248        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.967      0.966      0.986      0.766\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    114/999      21.6G    0.02742    0.02849    0.01228        211        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.976      0.967      0.987       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    115/999      21.6G     0.0276    0.02781    0.01202        205        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.958      0.944      0.978      0.761\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    116/999      21.6G    0.02751    0.02897     0.0116        228        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.962      0.949      0.982      0.774\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    117/999      21.6G    0.02731    0.02818    0.01087        212        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.977      0.955      0.985      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    118/999      21.6G    0.02773    0.02911    0.01147        245        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.967       0.95       0.98      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    119/999      21.6G    0.02736    0.02935    0.01085        230        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.962       0.95       0.98      0.774\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    120/999      21.6G    0.02697    0.03068    0.01094        295        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.976      0.959      0.987      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    121/999      21.6G    0.02659    0.02781    0.01093        204        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.975      0.936      0.981      0.784\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    122/999      21.6G    0.02701     0.0287    0.01032        212        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.971      0.963      0.984      0.771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    123/999      21.6G    0.02733    0.02891    0.01047        214        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.977       0.97      0.988      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    124/999      21.6G    0.02712    0.02812    0.01064        221        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.962      0.962      0.985       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    125/999      21.6G    0.02691    0.02866    0.01115        225        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.971      0.966      0.988      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    126/999      21.6G    0.02714    0.02787    0.01099        182        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.977      0.967      0.988       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    127/999      21.6G    0.02686    0.02775    0.01055        224        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.975      0.975      0.989      0.778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    128/999      21.6G     0.0266    0.02856    0.01054        237        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.982      0.977       0.99      0.786\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    129/999      21.6G    0.02767    0.02734    0.01049        213        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.982       0.97       0.99       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    130/999      21.6G    0.02746    0.02837    0.01018        211        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.98      0.972       0.99       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    131/999      21.6G    0.02691    0.02914    0.01028        247        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.967      0.967      0.986       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    132/999      21.6G    0.02601    0.02818    0.01073        211        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.974       0.97      0.987      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    133/999      21.6G    0.02687    0.02811   0.009906        222        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.978      0.979      0.988      0.786\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    134/999      21.6G    0.02641    0.02876   0.009578        238        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.975      0.962      0.988       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    135/999      21.6G    0.02673    0.02746   0.009543        211        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.985      0.975       0.99      0.786\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    136/999      21.6G    0.02654    0.02599   0.009859        172        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.975       0.98      0.989      0.771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    137/999      21.6G    0.02732    0.02806   0.009906        217        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.981       0.96      0.986      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    138/999      21.6G    0.02613    0.02809   0.009922        234        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.979      0.973      0.989      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    139/999      21.6G    0.02655     0.0278   0.009537        218        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.986      0.981       0.99      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    140/999      21.6G    0.02704    0.02698    0.00971        199        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.974      0.977       0.99      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    141/999      21.6G    0.02652    0.02818   0.009694        254        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.975      0.963      0.987      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    142/999      21.6G    0.02585    0.02669    0.01007        222        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.98      0.975      0.989      0.793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    143/999      21.6G    0.02635    0.02824   0.009595        220        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.981      0.977       0.99      0.797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    144/999      21.6G    0.02597    0.02663   0.009502        236        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.98      0.965      0.988      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    145/999      21.6G    0.02636    0.02805   0.009502        236        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.979      0.964      0.988       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    146/999      21.6G    0.02666    0.02857   0.008938        229        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.98      0.963      0.988      0.783\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    147/999      21.6G     0.0262    0.02771   0.008983        214        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.976      0.971      0.989      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    148/999      21.6G    0.02571     0.0279    0.00904        228        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.985      0.984      0.991       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    149/999      21.6G    0.02657    0.02755    0.00911        214        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.984      0.975       0.99      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    150/999      21.6G    0.02594    0.02732   0.008878        227        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.987      0.973      0.989      0.793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    151/999      21.6G    0.02557    0.02775   0.008943        232        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.987      0.976       0.99      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    152/999      21.6G    0.02607    0.02796   0.009365        230        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.981      0.983      0.991      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    153/999      21.6G    0.02596    0.02873   0.008798        250        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.981      0.973       0.99      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    154/999      21.6G    0.02527    0.02755   0.008879        255        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575       0.98      0.977      0.989      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    155/999      21.6G    0.02614    0.02763   0.009053        223        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.981       0.98       0.99      0.804\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    156/999      21.6G    0.02586    0.02641   0.009017        187        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.981       0.98       0.99      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    157/999      21.6G      0.026    0.02767   0.009278        221        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        400       1575      0.985      0.984      0.991      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "    158/999      21.6G     0.0261    0.02794   0.009064        211        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   ^C\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/public/b_it_bot_work/2d_perception/yolov5/train.py\", line 630, in <module>\n",
      "WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers\n",
      "    main(opt)\n",
      "  File \"/home/jovyan/public/b_it_bot_work/2d_perception/yolov5/train.py\", line 524, in main\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 101 closing signal SIGINT\n",
      "  File \"/home/jovyan/public/b_it_bot_work/2d_perception/yolov5/train.py\", line 348, in train\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 102 closing signal SIGINT\n",
      "    results, maps, _ = validate.run(data_dict,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/jovyan/public/b_it_bot_work/2d_perception/yolov5/val.py\", line 253, in run\n",
      "    correct = process_batch(predn, labelsn, iouv)\n",
      "  File \"/home/jovyan/public/b_it_bot_work/2d_perception/yolov5/val.py\", line 85, in process_batch\n",
      "    x = torch.where((iou >= iouv[i]) & correct_class)  # IoU > threshold and classes match\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if TRAIN:   \n",
    "    if FREEZE:\n",
    "        RES_DIR = set_res_dir()\n",
    "    \n",
    "        # training by freezing first 15 layers out of 25 layers       \n",
    "#         !python train.py \\\n",
    "#                 --batch 256 \\\n",
    "#                 --data ../dataset_ss22.yaml \\\n",
    "#                 --weights yolov5m.pt \\\n",
    "#                 --img 640 \\\n",
    "#                 --epochs {EPOCHS} \\\n",
    "#                 --name {RES_DIR} \\\n",
    "#                 --freeze 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14\n",
    "        \n",
    "        # trainig on multi GPUs\n",
    "        !python -m torch.distributed.run --nproc_per_node 2 train.py \\\n",
    "                --batch 512 \\\n",
    "                --data ../dataset_ss22_v4.yaml \\\n",
    "                --weights yolov5m.pt \\\n",
    "                --img 640 \\\n",
    "                --epochs {EPOCHS} \\\n",
    "                --name {RES_DIR} \\\n",
    "                --device 0,1 \\\n",
    "                --freeze 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14\n",
    "        \n",
    "        \n",
    "    \n",
    "#         # trainig using pretrained model (multi GPUs)\n",
    "#         !python -m torch.distributed.run --nproc_per_node 2 train.py \\\n",
    "#                 --batch 512 \\\n",
    "#                 --data ../dataset_ss22_v3.yaml \\\n",
    "#                 --resume /home/jovyan/public/logs/yolo5/train/results_22/weights/best.pt \\\n",
    "#                 --img 640 \\\n",
    "#                 --epochs {EPOCHS} \\\n",
    "#                 --name {RES_DIR} \\\n",
    "#                 --device 0,1 \\\n",
    "#                 --freeze 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14\n",
    "    \n",
    "    else:\n",
    "        RES_DIR = set_res_dir()\n",
    "        # training all layers of model\n",
    "        !python train.py --data ../dataset_ss22_v2.yaml --weights yolov5m.pt \\\n",
    "        --img 640 --epochs {EPOCHS} --batch-size 256 --name {RES_DIR}\n",
    "else:\n",
    "    # set the RES_DIR name\n",
    "    res_dir_count = '19' \n",
    "    RES_DIR = f\"/home/jovyan/public/logs/yolo5/train/results_{res_dir_count}\"\n",
    "    print(\"Set RES_DIR to: \", RES_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwfG5GQwqYoM"
   },
   "source": [
    "## Check Out the Validation Predictions and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyrImEH2qcN1"
   },
   "source": [
    "### Visualization and Inference Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEKKeFxpqfMs"
   },
   "outputs": [],
   "source": [
    "# Function to show validation predictions saved during training.\n",
    "def show_valid_results(RES_DIR):\n",
    "    !ls {RES_DIR}\n",
    "    EXP_PATH = f\"{RES_DIR}\"\n",
    "    validation_pred_images = glob.glob(f\"{EXP_PATH}/*_pred.jpg\")\n",
    "    print(validation_pred_images)\n",
    "    for pred_image in validation_pred_images:\n",
    "        image = cv2.imread(pred_image)\n",
    "        plt.figure(figsize=(19, 16))\n",
    "        plt.imshow(image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAF0wDI3qhJJ"
   },
   "source": [
    "The following functions are for carrying out inference on images and videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uy4VOSz0qifJ"
   },
   "outputs": [],
   "source": [
    "# Helper function for inference on images.\n",
    "def inference(RES_DIR, data_path):\n",
    "    # Directory to store inference results.\n",
    "    infer_dir_count = len(glob.glob('/home/jovyan/public/logs/yolo5/detect/*'))\n",
    "    print(f\"Current number of inference detection directories: {infer_dir_count}\")\n",
    "    INFER_DIR = f\"/home/jovyan/public/logs/yolo5/detect/inference_{infer_dir_count+1}\"\n",
    "    print(INFER_DIR)\n",
    "    # Inference on images.\n",
    "    !python detect.py --weights {RES_DIR}/weights/best.pt \\\n",
    "    --source {data_path} --name {INFER_DIR} --device 0\n",
    "    return INFER_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-j53ehiqmZU"
   },
   "outputs": [],
   "source": [
    "def visualize(INFER_DIR):\n",
    "# Visualize inference images.\n",
    "    INFER_PATH = f\"{INFER_DIR}\"\n",
    "    infer_images = glob.glob(f\"{INFER_PATH}/*\")\n",
    "    print(infer_images)\n",
    "    for pred_image in infer_images:\n",
    "        image = cv2.imread(pred_image)\n",
    "        plt.figure(figsize=(19, 16))\n",
    "        plt.imshow(image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtKTNNDoqqi3"
   },
   "source": [
    "**Visualize validation prediction images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "p_punILPqqWp",
    "outputId": "aeb5a1c2-f00c-4eee-f3ae-e7e82133aaba"
   },
   "outputs": [],
   "source": [
    "show_valid_results(RES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jurecthtqvj9"
   },
   "source": [
    "### Inference\n",
    "In this section, we will carry out inference on unseen images and videos from the internet. \n",
    "\n",
    "The images for inference are in the `inference_images` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTigK5v4q27c"
   },
   "source": [
    "**To carry out inference on images, we just need to provide the directory path where all the images are stored, and inference will happen on all images automatically.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0k-GZGFq4IS",
    "outputId": "5456023a-da3f-460e-bf0a-6c396d4d2928"
   },
   "outputs": [],
   "source": [
    "on_single_image = True\n",
    "\n",
    "if on_single_image:\n",
    "    # Inference on single image\n",
    "    IMAGE_INFER_DIR = inference(RES_DIR, '/home/jovyan/public/b_it_bot_work/2d_perception_test/inference_images/inference_img01/1562121558.622500193_raw_rgb.jpg')\n",
    "else:\n",
    "    # Inference on images.\n",
    "    IMAGE_INFER_DIR = inference(RES_DIR, '/home/jovyan/public/b_it_bot_work/2d_perception/day3_test_images')\n",
    "\n",
    "\n",
    "IMAGE_INFER_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JLDCTeBfq5jO",
    "outputId": "13fa46d6-fbaa-401e-e7cc-14c82b4e3b6b"
   },
   "outputs": [],
   "source": [
    "# IMAGE_INFER_DIR\n",
    "visualize(IMAGE_INFER_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model (.pt) to ONNX model (.onnx)\n",
    "###### Reference: https://learnopencv.com/object-detection-using-yolov5-and-opencv-dnn-in-c-and-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python export.py --weights /home/jovyan/public/logs/yolo5/train/results_28/weights/best.pt --include onnx"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "custom_object_detection_using_YOLOv5_opencv.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
